{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea690c2",
   "metadata": {},
   "source": [
    "# 1. Osnovne biblioteke i skup podataka za rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5725ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac784f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b40567",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('FinalAirlineReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88493c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalReview</th>\n",
       "      <th>FilteredReview</th>\n",
       "      <th>StemmedReview</th>\n",
       "      <th>LemmatizedReview</th>\n",
       "      <th>Sentiment2Cat</th>\n",
       "      <th>Sentiment3Cat</th>\n",
       "      <th>Sentiment4Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119835</th>\n",
       "      <td>We flew economy from Bangkok to HCMC (Saigon)....</td>\n",
       "      <td>flew economy bangkok hcmc saigon cabin dirties...</td>\n",
       "      <td>flew economi bangkok hcmc saigon cabin dirties...</td>\n",
       "      <td>flew economy bangkok hcmc saigon cabin dirties...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13105</th>\n",
       "      <td>The new Air France Business seat is full flat,...</td>\n",
       "      <td>new air france business seat full flat comfort...</td>\n",
       "      <td>new air franc busi seat full flat comfort prov...</td>\n",
       "      <td>new air france business seat full flat comfort...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38094</th>\n",
       "      <td>✅ , |  I flew the A380 of China Southern Airli...</td>\n",
       "      <td>flew china southern airlines lax guangzhou ret...</td>\n",
       "      <td>flew china southern airlin lax guangzhou retur...</td>\n",
       "      <td>flew china southern airline lax guangzhou retu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64173</th>\n",
       "      <td>JFK via FLL for a business trip - my only pref...</td>\n",
       "      <td>jfk via fll business trip preferred airline do...</td>\n",
       "      <td>jfk via fll busi trip prefer airlin domest cit...</td>\n",
       "      <td>jfk via fll business trip preferred airline do...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50635</th>\n",
       "      <td>✅ , |  Was overall happy with flights to Melbo...</td>\n",
       "      <td>overall happy flights melbourne london heathro...</td>\n",
       "      <td>overal happi flight melbourn london heathrow v...</td>\n",
       "      <td>overall happy flight melbourne london heathrow...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           OriginalReview  \\\n",
       "119835  We flew economy from Bangkok to HCMC (Saigon)....   \n",
       "13105   The new Air France Business seat is full flat,...   \n",
       "38094   ✅ , |  I flew the A380 of China Southern Airli...   \n",
       "64173   JFK via FLL for a business trip - my only pref...   \n",
       "50635   ✅ , |  Was overall happy with flights to Melbo...   \n",
       "\n",
       "                                           FilteredReview  \\\n",
       "119835  flew economy bangkok hcmc saigon cabin dirties...   \n",
       "13105   new air france business seat full flat comfort...   \n",
       "38094   flew china southern airlines lax guangzhou ret...   \n",
       "64173   jfk via fll business trip preferred airline do...   \n",
       "50635   overall happy flights melbourne london heathro...   \n",
       "\n",
       "                                            StemmedReview  \\\n",
       "119835  flew economi bangkok hcmc saigon cabin dirties...   \n",
       "13105   new air franc busi seat full flat comfort prov...   \n",
       "38094   flew china southern airlin lax guangzhou retur...   \n",
       "64173   jfk via fll busi trip prefer airlin domest cit...   \n",
       "50635   overal happi flight melbourn london heathrow v...   \n",
       "\n",
       "                                         LemmatizedReview Sentiment2Cat  \\\n",
       "119835  flew economy bangkok hcmc saigon cabin dirties...      Negative   \n",
       "13105   new air france business seat full flat comfort...      Positive   \n",
       "38094   flew china southern airline lax guangzhou retu...      Positive   \n",
       "64173   jfk via fll business trip preferred airline do...      Positive   \n",
       "50635   overall happy flight melbourne london heathrow...      Positive   \n",
       "\n",
       "       Sentiment3Cat       Sentiment4Cat  \n",
       "119835      Negative  Extremely Negative  \n",
       "13105       Positive  Extremely Positive  \n",
       "38094       Positive  Extremely Positive  \n",
       "64173       Positive  Extremely Positive  \n",
       "50635       Positive  Extremely Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81597a3b",
   "metadata": {},
   "source": [
    "# 2. Tf-Idf Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31577218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ReviewType(Enum):\n",
    "    Filtered = 1,\n",
    "    Stemmed = 2,\n",
    "    Lemmatized = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44581d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def bagOfWordsDataFrame(reviewType: ReviewType, numOfSentiments: int, maxFeatures: int):\n",
    "    \n",
    "    reviewAttribute = \"\"\n",
    "    sentimentAttribute = \"\"\n",
    "    \n",
    "    if reviewType == ReviewType.Filtered:\n",
    "        reviewAttribute = \"FilteredReview\"\n",
    "    elif reviewType == ReviewType.Stemmed:\n",
    "        reviewAttribute = \"StemmedReview\"\n",
    "    elif reviewType == ReviewType.Lemmatized:\n",
    "        reviewAttribute = \"LemmatizedReview\"\n",
    "    \n",
    "    if numOfSentiments == 2:\n",
    "        sentimentAttribute = \"Sentiment2Cat\"\n",
    "    elif numOfSentiments == 3:\n",
    "        sentimentAttribute = \"Sentiment3Cat\"\n",
    "    elif numOfSentiments == 4:\n",
    "        sentimentAttribute = \"Sentiment4Cat\"\n",
    "    \n",
    "    reviewList = data[reviewAttribute].to_list()\n",
    "    \n",
    "    tfIdfVector = TfidfVectorizer(max_features=maxFeatures)\n",
    "    \n",
    "    wordVectors = tfIdfVector.fit_transform(reviewList)\n",
    "    featureNames = tfIdfVector.get_feature_names_out()\n",
    "    \n",
    "    bowDataFrame = pd.DataFrame(wordVectors.toarray(), columns=featureNames)\n",
    "    \n",
    "    sentimentColumn = data[sentimentAttribute]\n",
    "    \n",
    "    bowDataFrame = pd.concat([bowDataFrame, sentimentColumn], axis=1)\n",
    "    \n",
    "    return bowDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddf28aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowData = bagOfWordsDataFrame(ReviewType.Filtered, 2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "715a3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bowData.iloc[:, :-1], bowData.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9984458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5f7990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xtest, ytr, ytest = train_test_split(x, y, test_size=0.25, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326bdb8",
   "metadata": {},
   "source": [
    "# 3. Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ef75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucitavamo neophodne biblioteke evaluaciju modela klasifikacije\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e981409",
   "metadata": {},
   "source": [
    "## 3.1 Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6f4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucitavamo biblioteke za rad sa Naivnim Bajesom\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "466571ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c923c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7323b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Negative', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionNB = naiveBayes.predict(xtest)\n",
    "predictionNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bed819e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy is: 84.71%\n",
      "Model's precision is: 84.91%\n",
      "Model's recall is: 84.71%\n",
      "Model's f1 is: 84.61%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model's accuracy is: {round(accuracy_score(predictionNB, ytest), 4)*100}%\")\n",
    "print(f\"Model's precision is: {round(precision_score(predictionNB, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's recall is: {round(recall_score(predictionNB, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's f1 is: {round(f1_score(predictionNB, ytest, average='weighted'), 4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e201fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.90      0.87     16908\n",
      "    Positive       0.87      0.78      0.82     14167\n",
      "\n",
      "    accuracy                           0.85     31075\n",
      "   macro avg       0.85      0.84      0.84     31075\n",
      "weighted avg       0.85      0.85      0.85     31075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionNB, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc2bc4",
   "metadata": {},
   "source": [
    "## 3.2 Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493105ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9f48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtModel = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82292c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1202a76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative', 'Negative', ..., 'Negative', 'Negative',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionDT = dtModel.predict(xtest)\n",
    "predictionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a63ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy is: 82.28%\n",
      "Model's precision is: 82.31%\n",
      "Model's recall is: 82.28%\n",
      "Model's f1 is: 82.3%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model's accuracy is: {round(accuracy_score(predictionDT, ytest), 4)*100}%\")\n",
    "print(f\"Model's precision is: {round(precision_score(predictionDT, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's recall is: {round(recall_score(predictionDT, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's f1 is: {round(f1_score(predictionDT, ytest, average='weighted'), 4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59c65b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.85      0.85     18481\n",
      "    Positive       0.78      0.79      0.78     12594\n",
      "\n",
      "    accuracy                           0.82     31075\n",
      "   macro avg       0.82      0.82      0.82     31075\n",
      "weighted avg       0.82      0.82      0.82     31075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionDT, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ab797",
   "metadata": {},
   "source": [
    "## 3.3 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45770957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ca78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ac5087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e0d65db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Negative', ..., 'Positive', 'Positive',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionLR = lrModel.predict(xtest)\n",
    "predictionLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b154f55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy is: 92.36%\n",
      "Model's precision is: 92.4%\n",
      "Model's recall is: 92.36%\n",
      "Model's f1 is: 92.36999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model's accuracy is: {round(accuracy_score(predictionLR, ytest), 4)*100}%\")\n",
    "print(f\"Model's precision is: {round(precision_score(predictionLR, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's recall is: {round(recall_score(predictionLR, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's f1 is: {round(f1_score(predictionLR, ytest, average='weighted'), 4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bd38b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.93      0.94     18617\n",
      "    Positive       0.90      0.91      0.91     12458\n",
      "\n",
      "    accuracy                           0.92     31075\n",
      "   macro avg       0.92      0.92      0.92     31075\n",
      "weighted avg       0.92      0.92      0.92     31075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictionLR, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81a7fd",
   "metadata": {},
   "source": [
    "## 3.4 Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "852e6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a78fee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbModel = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "879d0722",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16552\\3524830440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgbModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbModel.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a382fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionGB = gbModel.predict(xtest)\n",
    "predictionGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9082144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model's accuracy is: {round(accuracy_score(predictionGB, ytest), 4)*100}%\")\n",
    "print(f\"Model's precision is: {round(precision_score(predictionGB, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's recall is: {round(recall_score(predictionGB, ytest, average='weighted'), 4)*100}%\")\n",
    "print(f\"Model's f1 is: {round(f1_score(predictionGB, ytest, average='weighted'), 4)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictionGB, ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
